{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n# Design of Experiments and Machine Learning model building\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Objective\n\nWater enters a Mixing Elbow from two Inlets; Hot (313 K) and Cold (293 K) and exits\nfrom Outlet. Using PyFluent in the background, this example runs Design of Experiments\nwith Cold Inlet Velocity and Hot Inlet Velocity as Input Parameters and Outlet\nTemperature as an Output Parameter.\n\nResults can be visualized using a Response Surface. Finally, Supervised Machine\nLearning Regression Task is performed to build the ML Model.\n\nThis example demonstrates:\n\n* Design of Experiment, Fluent setup and simulation using PyFluent.\n* Building of Supervised Machine Learning Model.\n\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Import required libraries/modules\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "# flake8: noqa: E402\n\nfrom pathlib import Path\n\nimport matplotlib.pyplot as plt\nimport numpy as np\nimport pandas as pd\nimport plotly.express as px\nimport plotly.graph_objects as go\nimport seaborn as sns\nimport tensorflow as tf\nfrom tensorflow import keras\n\nimport ansys.fluent.core as pyfluent\nfrom ansys.fluent.core import examples"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Specifying save path\n* save_path can be specified as Path(\"E:/\", \"pyfluent-examples-tests\") or\n* Path(\"E:/pyfluent-examples-tests\") in a Windows machine for example,  or\n* Path(\"~/pyfluent-examples-tests\") in Linux.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "save_path = Path(pyfluent.EXAMPLES_PATH)\n\nimport_filename = examples.download_file(\n    \"elbow.cas.h5\",\n    \"pyfluent/examples/DOE-ML-Mixing-Elbow\",\n    save_path=save_path,\n)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Fluent Solution Setup\n\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Launch Fluent session with solver mode and print Fluent version\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "solver = pyfluent.launch_fluent(\n    precision=\"double\",\n    processor_count=2,\n    version=\"3d\",\n)\nprint(solver.get_fluent_version())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Read case\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "solver.settings.file.read_case(file_name=import_filename)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Design of Experiments\n* Define Manual DOE as numpy arrays\n* Run cases in sequence\n* Populate results (Mass Weighted Average of Temperature at Outlet) in resArr\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "coldVelArr = np.array([0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7])\nhotVelArr = np.array([0.8, 1, 1.2, 1.4, 1.6, 1.8, 2.0])\nresArr = np.zeros((coldVelArr.shape[0], hotVelArr.shape[0]))\n\nfor idx1, coldVel in np.ndenumerate(coldVelArr):\n    for idx2, hotVel in np.ndenumerate(hotVelArr):\n        cold_inlet = solver.settings.setup.boundary_conditions.velocity_inlet[\n            \"cold-inlet\"\n        ]\n        cold_inlet.momentum.velocity.value = coldVel\n\n        hot_inlet = solver.settings.setup.boundary_conditions.velocity_inlet[\n            \"hot-inlet\"\n        ]\n        hot_inlet.momentum.velocity.value = hotVel\n\n        solver.settings.solution.initialization.initialization_type = \"standard\"\n        solver.settings.solution.initialization.standard_initialize()\n        solver.settings.solution.run_calculation.iterate(iter_count=200)\n\n        res_tui = solver.scheme_eval.exec(\n            (\n                \"(ti-menu-load-string \"\n                '\"/report/surface-integrals/mass-weighted-avg outlet () '\n                'temperature no\")',\n            )\n        )\n        resArr[idx1][idx2] = eval(res_tui.split(\" \")[-1])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Close the session\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "solver.exit()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Plot Response Surface using Plotly\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "fig = go.Figure(data=[go.Surface(z=resArr.T, x=coldVelArr, y=hotVelArr)])\n\nfig.update_layout(\n    title={\n        \"text\": \"Mixing Elbow Response Surface\",\n        \"y\": 0.9,\n        \"x\": 0.5,\n        \"xanchor\": \"center\",\n        \"yanchor\": \"top\",\n    }\n)\n\nfig.update_layout(\n    scene=dict(\n        xaxis_title=\"Cold Inlet Vel (m/s)\",\n        yaxis_title=\"Hot Inlet Vel (m/s)\",\n        zaxis_title=\"Outlet Temperature (K)\",\n    ),\n    width=600,\n    height=600,\n    margin=dict(l=80, r=80, b=80, t=80),\n)\nfig.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Supervised ML for a Regression Task\n\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Create Pandas Dataframe for ML Model Input\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "coldVelList = []\nhotVelList = []\nResultList = []\n\nfor idx1, coldVel in np.ndenumerate(coldVelArr):\n    for idx2, hotVel in np.ndenumerate(hotVelArr):\n        coldVelList.append(coldVel)\n        hotVelList.append(hotVel)\n        ResultList.append(resArr[idx1][idx2])\n\ntempDict = {\"coldVel\": coldVelList, \"hotVel\": hotVelList, \"Result\": ResultList}\n\ndf = pd.DataFrame.from_dict(tempDict)\n\nfrom sklearn.compose import ColumnTransformer\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.preprocessing import PolynomialFeatures, StandardScaler"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Using scikit-learn\n* Prepare Features (X) and Label (y) using a Pre-Processing Pipeline\n* Train-Test (80-20) Split\n* Add Polynomial Features to improve ML Model\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "poly_features = PolynomialFeatures(degree=2, include_bias=False)\n\ntransformer1 = Pipeline(\n    [\n        (\"poly_features\", poly_features),\n        (\"std_scaler\", StandardScaler()),\n    ]\n)\n\n\nx_ct = ColumnTransformer(\n    [\n        (\"transformer1\", transformer1, [\"coldVel\", \"hotVel\"]),\n    ],\n    remainder=\"drop\",\n)\n\ntrain_set, test_set = train_test_split(df, test_size=0.2, random_state=42)\n\nX_train = x_ct.fit_transform(train_set)\nX_test = x_ct.fit_transform(test_set)\n\ny_train = train_set[\"Result\"]\ny_test = test_set[\"Result\"]\ny_train = np.ravel(y_train.T)\ny_test = np.ravel(y_test.T)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "* Define functions for:\n* Cross-Validation and Display Scores (scikit-learn)\n* Training the Model (scikit-learn)\n* Prediction on Unseen/Test Data (scikit-learn)\n* Parity Plot (Matplotlib and Seaborn)\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "# from pprint import pprint\n\n# from sklearn.ensemble import RandomForestRegressor\n# from sklearn.linear_model import LinearRegression\nfrom sklearn.metrics import r2_score\nfrom sklearn.model_selection import RepeatedKFold, cross_val_score\nfrom xgboost import XGBRegressor\n\nnp.set_printoptions(precision=2)\n\n\ndef display_scores(scores):\n    \"\"\"Display scores.\"\"\"\n    print(\"\\nCross-Validation Scores:\", scores)\n    print(\"Mean:%0.2f\" % (scores.mean()))\n    print(\"Std. Dev.:%0.2f\" % (scores.std()))\n\n\ndef fit_and_predict(model):\n    \"\"\"Fit abd predict.\"\"\"\n    cv = RepeatedKFold(n_splits=5, n_repeats=3, random_state=42)\n    cv_scores = cross_val_score(\n        model, X_train, y_train, scoring=\"neg_mean_squared_error\", cv=cv\n    )\n    rmse_scores = np.sqrt(-cv_scores)\n    display_scores(rmse_scores)\n\n    model.fit(X_train, y_train)\n    train_predictions = model.predict(X_train)\n    test_predictions = model.predict(X_test)\n    print(train_predictions.shape[0])\n    print(\"\\n\\nCoefficient Of Determination\")\n    print(\"Train Data R2 Score: %0.3f\" % (r2_score(train_predictions, y_train)))\n    print(\"Test Data R2 Score: %0.3f\" % (r2_score(test_predictions, y_test)))\n    print(\n        \"\\n\\nPredictions - Ground Truth (Kelvin): \", (test_predictions - y_test), \"\\n\"\n    )\n    #    print(\"\\n\\nModel Parameters:\")\n    #    pprint(model.get_params())\n\n    com_train_set = train_set\n    com_test_set = test_set\n\n    train_list = []\n    for i in range(train_predictions.shape[0]):\n        train_list.append(\"Train\")\n\n    test_list = []\n    for i in range(test_predictions.shape[0]):\n        test_list.append(\"Test\")\n\n    com_train_set[\"Result\"] = train_predictions.tolist()\n    com_train_set[\"Set\"] = train_list\n    com_test_set[\"Result\"] = test_predictions.tolist()\n    com_test_set[\"Set\"] = test_list\n\n    df_combined = pd.concat([com_train_set, com_test_set])\n\n    df_combined.to_csv(\"PyFluent_Output.csv\", header=True, index=False)\n\n    fig = plt.figure(figsize=(12, 5))\n\n    fig.add_subplot(121)\n    sns.regplot(x=y_train, y=train_predictions, color=\"g\")\n    plt.title(\"Train Data\", fontsize=16)\n    plt.xlabel(\"Ground Truth\", fontsize=12)\n    plt.ylabel(\"Predictions\", fontsize=12)\n\n    fig.add_subplot(122)\n    sns.regplot(x=y_test, y=test_predictions, color=\"g\")\n    plt.title(\"Unseen Data\", fontsize=16)\n    plt.xlabel(\"Ground Truth\", fontsize=12)\n    plt.ylabel(\"Predictions\", fontsize=12)\n\n    plt.tight_layout()\n    plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Select the Model from Linear, Random Forest or XGBoost\n* Call fit_and_predict\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "# model = LinearRegression()\nmodel = XGBRegressor(\n    n_estimators=100, max_depth=10, eta=0.3, subsample=0.8, random_state=42\n)\n# model = RandomForestRegressor(random_state=42)\n\nfit_and_predict(model)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Show graph\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "<img src=\"file://../../_static/doe_ml_predictions_regression.png\" align=\"center\" alt=\"Regression Model Predictions\">\n\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Regression Model Predictions\n\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 3D Visualization of Model Predictions on Train & Test Set\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "df = pd.read_csv(\"PyFluent_Output.csv\")\n\nfig = px.scatter_3d(df, x=\"coldVel\", y=\"hotVel\", z=\"Result\", color=\"Set\")\nfig.update_traces(marker=dict(size=4))\nfig.update_layout(legend=dict(yanchor=\"top\", y=1, xanchor=\"left\", x=0.0))\n\nfig.add_traces(go.Surface(z=resArr.T, x=coldVelArr, y=hotVelArr))\n\nfig.update_layout(\n    title={\n        \"text\": \"Mixing Elbow Response Surface\",\n        \"y\": 0.9,\n        \"x\": 0.5,\n        \"xanchor\": \"center\",\n        \"yanchor\": \"top\",\n    }\n)\n\nfig.update_layout(\n    scene=dict(\n        xaxis_title=\"Cold Inlet Vel (m/s)\",\n        yaxis_title=\"Hot Inlet Vel (m/s)\",\n        zaxis_title=\"Outlet Temperature (K)\",\n    ),\n    width=500,\n    height=500,\n    margin=dict(l=80, r=80, b=80, t=80),\n)\n\nfig.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## TensorFlow and Keras Neural Network Regression\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "print(\"TensorFlow version is:\", tf.__version__)\nkeras.backend.clear_session()\nnp.random.seed(42)\ntf.random.set_seed(42)\n\nmodel = keras.models.Sequential(\n    [\n        keras.layers.Dense(\n            20,\n            activation=\"relu\",\n            input_shape=X_train.shape[1:],\n            kernel_initializer=\"lecun_normal\",\n        ),\n        keras.layers.BatchNormalization(),\n        keras.layers.Dense(20, activation=\"relu\", kernel_initializer=\"lecun_normal\"),\n        keras.layers.BatchNormalization(),\n        keras.layers.Dense(20, activation=\"relu\", kernel_initializer=\"lecun_normal\"),\n        keras.layers.BatchNormalization(),\n        keras.layers.Dense(1),\n    ]\n)\n\noptimizer = tf.keras.optimizers.Adam(learning_rate=0.1, beta_1=0.9, beta_2=0.999)\n\nmodel.compile(loss=\"mean_squared_error\", optimizer=optimizer)\ncheckpoint_cb = keras.callbacks.ModelCheckpoint(\n    \"my_keras_model.h5\", save_best_only=True\n)\nearly_stopping_cb = keras.callbacks.EarlyStopping(\n    patience=30, restore_best_weights=True\n)\n\nmodel.summary()\n\n# keras.utils.plot_model(model, show_shapes=True,) # to_file='dot_img.png', )\n\nhistory = model.fit(\n    X_train,\n    y_train,\n    epochs=250,\n    validation_split=0.2,\n    callbacks=[checkpoint_cb, early_stopping_cb],\n)\nmodel = keras.models.load_model(\"my_keras_model.h5\")\n\nprint(history.params)\n\npd.DataFrame(history.history).plot(figsize=(8, 5))\nplt.grid(True)\nplt.show()\n\ntrain_predictions = model.predict(X_train)\ntest_predictions = model.predict(X_test)\ntrain_predictions = np.ravel(train_predictions.T)\ntest_predictions = np.ravel(test_predictions.T)\nprint(test_predictions.shape)\n\nprint(\"\\n\\nTrain R2: %0.3f\" % (r2_score(train_predictions, y_train)))\nprint(\"Test R2: %0.3f\" % (r2_score(test_predictions, y_test)))\nprint(\"Predictions - Ground Truth (Kelvin): \", (test_predictions - y_test))\n\nfig = plt.figure(figsize=(12, 5))\n\nfig.add_subplot(121)\nsns.regplot(x=y_train, y=train_predictions, color=\"g\")\nplt.title(\"Train Data\", fontsize=16)\nplt.xlabel(\"Ground Truth\", fontsize=12)\nplt.ylabel(\"Predictions\", fontsize=12)\n\nfig.add_subplot(122)\nsns.regplot(x=y_test, y=test_predictions, color=\"g\")\nplt.title(\"Test/Unseen Data\", fontsize=16)\nplt.xlabel(\"Ground Truth\", fontsize=12)\nplt.ylabel(\"Predictions\", fontsize=12)\n\nplt.tight_layout()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Show graph\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "<img src=\"file://../../_static/doe_ml_validation_loss.png\" align=\"center\" alt=\"Neural Network Validation Loss\">\n\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Neural Network Validation Loss\n\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "<img src=\"file://../../_static/doe_ml_predictions_neural_network.png\" align=\"center\" alt=\"Neural Network Predictions\">\n\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Neural Network Predictions\n\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.11"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}